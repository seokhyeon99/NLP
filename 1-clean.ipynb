{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Text\n",
    "convert text string into list of tokens (words)\n",
    "\n",
    "text replace vs. regular expressions\n",
    "- remove HTML characters (`&apos;`, `&amp;` ,`&lt`; etc. )\n",
    "- Remove Unicode Characters  (\\u015b)\n",
    "- Removing URLs, Hashtags, Punctuation, Mentions, etc.\n",
    "- Case Normalization (lowercase)\n",
    " \n",
    "- tokenization\n",
    "- stemming, lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the small test text\n",
    "text = \"\"\"Hi! I'm Michelle and I'm 22.\n",
    "I really,really like this guy. He's 27 and everything  I like in a guy. We have so much in common.\n",
    "We met around three and a half months ago. A week after we met, he texted me and we didn't stop talking for a whole month and a half. We talked day and night, sometimes 'til four in the morning.\n",
    "Then, he started ignoring me. When that started to  happen, a red flag went up in my head, so I started ignoring him, too. Except I started missing him.\n",
    "Before I started a new semester, I asked him what was the point of saving my number if he wasn't going to ask me out. (Yes, we haven't gone out on a date yet. We've talked about it, but he doesn't make it happen.)\n",
    "I told him I wasn't going to have enough time for him, and if he really wanted to go out with me, he should make it happen soon rather than later.\n",
    "\n",
    "I just don't understand why he hasn't asked me out yet. He gives me the money excuse, or the \"every time I want to, something else comes up\" excuse.\n",
    "If he wants to see me he should've done so already... right?\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text has 206 tokens, 136 types\n",
      "Tokenizer makes 297 tokens, 128 types as follows:\n",
      "{'', 'for', 'Before', 'excuse', 'of', 'did', 'the', 'him', 'what', 'happen', 'should', 'four', 'me', 'so', 'to', 'If', 'right?', 'this', 'about', 'something', 'half', 'done', 'red', 'go', 'soon', 'my', 'morning', 'guy', 'already', 'around', 'do', 'everything', 'Yes', 'not', 'does', 'We', 'he', 'head', 'up', 'wanted', 'gives', 'in', 'or', 'much', 'after', \"'ve\", 'stop', 'time', 'just', 'Michelle', 'talked', 'common', 'enough', ',', 'we', 'was', 'new', 'like', 'and', 'yet', 'want', 'but', 'sometimes', 'ago', 'that', 'understand', 'point', 'went', 'date', 'it', 'texted', 'ignoring', '(', 'wants', 'talking', 'saving', 'have', 'comes', 'started', 'on', 'money', 'Hi!', 'day', 'than', 'really', 'asked', 'number', 'too', 'three', 'if', 'night', 'rather', 'gone', 'semester', 'a', 'met', \"'til\", 'months', 'up\"', 'else', 'flag', \"'s\", '.', 'He', \"'m\", 'why', ')', 'ask', '22', 'I', 'missing', 'month', 'with', 'see', 'week', 'Except', 'later', 'When', 'has', 'out', 'going', 'told', 'Then', 'make', 'whole', '\"every', '27', 'A'}\n"
     ]
    }
   ],
   "source": [
    "# check how many tokens has text:\n",
    "x=text.split(\" \")\n",
    "print(f\"Text has {len(x)} tokens, {len(set(x))} types\")\n",
    "\n",
    "# copy\n",
    "text1 = text\n",
    "\n",
    "# task tokenize text\n",
    "text1 = text1.replace(\".\", \" . \")\n",
    "text1 = text1.replace(\":\", \" : \")\n",
    "text1 = text1.replace(\"n\\'t\", \" not\")\n",
    "text1 = text1.replace(\"'\", \" '\")\n",
    "text1 = text1.replace(\"\\n\", \" \")\n",
    "text1 = text1.replace(\"(\", \" ( \")\n",
    "text1 = text1.replace(\")\", \" ) \")\n",
    "text1 = text1.replace(\",\", \" , \")\n",
    "\n",
    "\n",
    "# develop more tokenization rules e.g. for !, \\n, ., \", etc.\n",
    "\n",
    "\n",
    "# check how many tokens you have:\n",
    "tok=text1.split(\" \")\n",
    "print(f\"Tokenizer makes {len(tok)} tokens, {len(set(tok))} types as follows:\\n{set(tok)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 정규식 간단한 요약 ## \n",
    "# ^ 라인의 처음을 매칭 \n",
    "# $ 라인의 끝을 매칭 \n",
    "# . 임의의 문자를 매칭 (와일드 카드) \n",
    "# \\s 공백 문자를 매칭 \n",
    "# \\S 공백이 아닌 문자를 매칭 \n",
    "# * 바로 앞선 문자에 적용되고 0 혹은 그 이상의 앞선 문자와 매칭을 표기함. \n",
    "# *? 바로 앞선 문자에 적용되고 0 혹은 그 이상의 앞선 문자와 매칭을 탐욕적이지 않은 방식으로 표기함. \n",
    "# + 바로 앞선 문자에 적용되고 1 혹은 그 이상의 앞선 문자와 매칭을 표기함 # +? 바로 앞선 문자에 적용되고 1 혹은 그 이상의 앞선 문자와 매칭을 탐욕적이지 않은 방식으로 표기함. \n",
    "# [aeiou] 명세된 집합 문자에 존재하는 단일 문자와 매칭. “a”, “e”, “i”, “o”, “u” 문자만 매칭되는 예제 \n",
    "# [a-z0-9] - 기호로 문자 범위를 명세할 수 있다. 소문자이거나 숫자인 단일 문자만 매칭되는 예제. \n",
    "# ( ) 괄호가 정규표현식에 추가될 때, 매칭을 무시한다. 하지만 findall()을 사용 할 때 전체 문자열보다 매칭된 문자열의 상세한 부속 문자열을 추출할 수 있게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this guy. He's 27 a\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# returns only the first match\n",
    "#m = re.search(r\"t.*a\", text)\n",
    "\n",
    "# non-greedy\n",
    "m = re.search(r\"t.*?a\", text)\n",
    "\n",
    "if m:\n",
    "    print(m.group())\n",
    "else:\n",
    "    print(\"nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "really,really like this guy. He's 27 and everything  I like in a guy. We have so much in common.\n",
      "We met around three and a half months ago. A week after we met, he texted me and we didn't stop talking for a whole month and a half. We talked day and night, sometimes 'til four in the morning.\n",
      "Then, he started ignoring me. When that started to  happen, a red flag went up in my head, so I started ignoring him, too. Except I started missing him.\n",
      "Before I started a new semester, I asked him what was the point of saving my number if he wasn't going to ask me out. (Yes, we haven't gone out on a date yet. We've talked about it, but he doesn't make it happen.)\n",
      "I told him I wasn't going to have enough time for him, and if he really\n"
     ]
    }
   ],
   "source": [
    "#Search per line\n",
    "#m = re.search(\"really.*really.*really\", text)\n",
    "\n",
    "#Search across line\n",
    "m = re.search(\"really.*really.*really\", text, re.DOTALL)\n",
    "if m:\n",
    "    print(m.group())\n",
    "else:\n",
    "    print(\"nothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## findall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"this guy. He's 27 a\", 'thing  I like in a', 't a', 'three a', 'ths a', 'ter we met, he texted me a', 't stop ta', 'th a', 'ta', 'ta', 'ted ignoring me. When tha', 't sta', 'ted to  ha', 't up in my hea', 'ta', 'ted ignoring him, too. Except I sta', 'ta', 'ted a', 'ter, I a', 't wa', 'the point of sa', 't going to a', 't. (Yes, we ha', 't gone out on a', \"te yet. We've ta\", \"t it, but he doesn't ma\", 't ha', 'told him I wa', 't going to ha', 'time for him, a', 'ted to go out with me, he should ma', 't ha', 'ther tha', \"t don't understa\", 't a', 't yet. He gives me the money excuse, or the \"every time I wa', \"ts to see me he should've done so a\"]\n"
     ]
    }
   ],
   "source": [
    "# greedy match\n",
    "#m = re.findall(r\"t.*a\", text)\n",
    "\n",
    "# all matches\n",
    "m = re.findall(r\"t.*?a\", text)\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Miche', 'll', 'e'), ('rea', 'll', 'y'), ('rea', 'll', 'y'), ('rea', 'll', 'y')]\n"
     ]
    }
   ],
   "source": [
    "# words that contain \"ll\"\n",
    "m = re.findall(\"([A-Za-z]*)(ll)([A-Za-z]*)\", text)\n",
    "\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Michelle ', 'll', 'l'),\n",
       " (' 22.\\nI ', '22', '2'),\n",
       " (' common.\\nWe ', 'mm', 'm'),\n",
       " (' three ', 'ee', 'e'),\n",
       " (' week ', 'ee', 'e'),\n",
       " (' happen, ', 'pp', 'p'),\n",
       " (' too. ', 'oo', 'o'),\n",
       " (' missing ', 'ss', 's'),\n",
       " (' happen.)\\nI ', 'pp', 'p'),\n",
       " (' really ', 'll', 'l'),\n",
       " (' happen ', 'pp', 'p'),\n",
       " (' see ', 'ee', 'e')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all words with double characters\n",
    "re.findall(r\"( [^ ]*((\\w)\\3)[^ ]* )\", text) #\\3: third buffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substitute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi !  I 'm Michelle and I 'm 22 . \n",
      "I really , really like this guy .  He 's 27 and everything  I like in a guy .  We have so much in common . \n",
      "We met around three and a half months ago .  A week after we met ,  he texted me and we didn 't stop talking for a whole month and a half .  We talked day and night ,  sometimes  'til four in the morning . \n",
      "Then ,  he started ignoring me .  When that started to  happen ,  a red flag went up in my head ,  so I started ignoring him ,  too .  Except I started missing him . \n",
      "Before I started a new semester ,  I asked him what was the point of saving my number if he wasn 't going to ask me out .   ( Yes ,  we haven 't gone out on a date yet .  We 've talked about it ,  but he doesn 't make it happen .) \n",
      "I told him I wasn 't going to have enough time for him ,  and if he really wanted to go out with me ,  he should make it happen soon rather than later . \n",
      "\n",
      "I just don 't understand why he hasn 't asked me out yet .  He gives me the money excuse ,  or the  \" every time I want to ,  something else comes up \"  excuse . \n",
      "If he wants to see me he should 've done so already ...  right?\n"
     ]
    }
   ],
   "source": [
    "# substitute token separators\n",
    "s = re.sub(\"([\\'])\", r\" \\1\", text)\n",
    "s = re.sub(\"([.!,()\\\"]+)\", r\" \\1 \", s)\n",
    "print(s)\n",
    "\n",
    "# task \n",
    "# find all token sparators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Simone Biles: 'I blame system that enabled Larry Nassar abuse'Published1 hour ago\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove HTML\n",
    "msg = '''<article class=\"ssrcss-xalfp3-ArticleWrapper e1nh2i2l6\"><header class=\"ssrcss-18mgjmu-HeadingWrapper e1nh2i2l5\"><h1 tabindex=\"-1\" id=\"main-heading\" class=\"ssrcss-1lgj0ki-StyledHeading e1fj1fc10\">Simone Biles: 'I blame system that enabled Larry Nassar abuse'</h1><div><dl class=\"ssrcss-7m91jz-MetadataStrip e1ojgjhb2\"><div class=\"ssrcss-8d0yke-MetadataStripItem e1ojgjhb1\"><dt class=\"ssrcss-1f39n02-VisuallyHidden e1y6uwnp0\">Published</dt><dd class=\"ssrcss-m5j4pi-MetadataContent e1ojgjhb0\"><span class=\"ssrcss-8g95ls-MetadataSnippet ecn1o5v2\"><time data-testid=\"timestamp\" datetime=\"2021-09-15T15:49:06.000Z\"><span data-testid=\"time-and-date:clock\" class=\"ssrcss-1cyelkp-IconContainer ecn1o5v0\"><svg viewBox=\"0 0 32 32\" width=\"1em\" height=\"1em\" class=\"ssrcss-xi5oyi-StyledIcon e6m7o991\" focusable=\"false\" aria-hidden=\"true\"><path d=\"M16 31c8.5 0 15-6.5 15-15S24.5 1 16 1 1 7.5 1 16s6.5 15 15 15zm0-2.7C9 28.3 3.7 23 3.7 16S9 3.7 16 3.7C23 3.7 28.3 9 28.3 16S23 28.3 16 28.3zm6.2-6.7l1-1.5-5.7-4.5-.6-8.6H15l-.7 10.5 7.9 4.1z\"></path></svg></span>1 hour ago</time></span></dd></div></dl></div><div class=\"ssrcss-xa24e7-TagShareWrapper e1nh2i2l0\"><div class=\"ssrcss-1ynay8h-StyledInformationPanel e15ad6a66\"><div><button width=\"content-length\" type=\"button\" aria-haspopup=\"true\" aria-expanded=\"false\" class=\"ssrcss-d4g1xj-Button etotop31\"><span data-testid=\"actions:share\" class=\"ssrcss-1a1fy59-IconWrapper etotop30\">'''\n",
    "re.sub(\"<[^>]*>\", \"\" , msg)#^: not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'start in the morning with --URL--'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove urls\n",
    "msg = '''start in the morning with https://www.bbc.co.uk/usingthebbc/terms/can-i-share-things-from-the-bbc'''\n",
    "re.sub(\"https?:\\/\\/.*[\\r\\n]*\", \"--URL--\", msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For example, HT and HT were used across social media platforms, including LinkedIn, on International Women’s Day.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task:\n",
    "# removing hashtags \n",
    "msg = '''For example, #EachforEqual and #IWD2020 were used across social media platforms, including LinkedIn, on International Women’s Day.'''\n",
    "\n",
    "re.sub(r\"#[^ ]*\", \"HT\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer makes 259 tokens, 131 types as follows:\n",
      "['!', '\"', \"'m\", \"'s\", \"'t\", \"'til\", \"'ve\", '(', ',', '.', '.)', '...', '22', '27', 'A', 'Before', 'Except', 'He', 'Hi', 'I', 'If', 'Michelle', 'Then', 'We', 'When', 'Yes', 'a', 'about', 'after', 'ago', 'already', 'and', 'around', 'ask', 'asked', 'but', 'comes', 'common', 'date', 'day', 'didn', 'doesn', 'don', 'done', 'else', 'enough', 'every', 'everything', 'excuse', 'flag', 'for', 'four', 'gives', 'go', 'going', 'gone', 'guy', 'half', 'happen', 'hasn', 'have', 'haven', 'he', 'head', 'him', 'if', 'ignoring', 'in', 'it', 'just', 'later', 'like', 'make', 'me', 'met', 'missing', 'money', 'month', 'months', 'morning', 'much', 'my', 'new', 'night', 'number', 'of', 'on', 'or', 'out', 'point', 'rather', 'really', 'red', 'right?', 'saving', 'see', 'semester', 'should', 'so', 'something', 'sometimes', 'soon', 'started', 'stop', 'talked', 'talking', 'texted', 'than', 'that', 'the', 'this', 'three', 'time', 'to', 'told', 'too', 'understand', 'up', 'want', 'wanted', 'wants', 'was', 'wasn', 'we', 'week', 'went', 'what', 'whole', 'why', 'with', 'yet']\n"
     ]
    }
   ],
   "source": [
    "# tokenize Michelle text\n",
    "#text1 = re.sub(\"([\\.!?',)(\\\"])\", r\" \\1 \", text)\n",
    "text1 = re.sub(\"([\\'])\", r\" \\1\", text)\n",
    "text1 = re.sub(\"([.!,()\\\"]+)\", r\" \\1 \", text1)\n",
    "\n",
    "# delete double whitespaces\n",
    "#text1 = re.sub(\"(\\s+)\", r\" \", text1)\n",
    "\n",
    "# tokenization at whitspace\n",
    "tok = re.split(\"\\s+\", text1)\n",
    "print(f\"Tokenizer makes {len(tok)} tokens, {len(set(tok))} types as follows:\\n{sorted(set(tok))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('everyth', 'ing'), ('someth', 'ing'), ('sav', 'ing'), ('miss', 'ing'), ('go', 'ing'), ('talk', 'ing'), ('ignor', 'ing')}\n"
     ]
    }
   ],
   "source": [
    "# word ending on .*ing\n",
    "m = re.findall(\"([a-z]*)(ing) \", text)\n",
    "\n",
    "print(set(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text', 'ed'),\n",
       " ('talk', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('r', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('ask', 'ed'),\n",
       " ('talk', 'ed'),\n",
       " ('want', 'ed'),\n",
       " ('ask', 'ed')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"([a-z]*)(ed) \", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text', 'ed'),\n",
       " ('talk', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('r', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('start', 'ed'),\n",
       " ('ask', 'ed'),\n",
       " ('talk', 'ed'),\n",
       " ('want', 'ed'),\n",
       " ('ask', 'ed')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#strip off *ed ()\n",
    "re.findall(\"(\\w*)(ed) \", text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple stemmer\n",
    "def stemming(word):\n",
    "    word = re.sub(\"ed$\", '', word)\n",
    "    word = re.sub(\"ing$\", '', word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming(\"walked\")\n",
    "#stemming(\"walking\")\n",
    "\n",
    "\n",
    "# how can we make sure that only the 'ed' at the end of the string is choped off?\n",
    "stemming(\"edited\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer makes 275 tokens, 127 types as follows:\n",
      "['!', '\"', \"'\", '(', ')', ',', '.', '22', '27', 'A', 'Before', 'Except', 'He', 'Hi', 'I', 'If', 'Michelle', 'Then', 'We', 'When', 'Yes', 'a', 'about', 'after', 'ago', 'already', 'and', 'around', 'ask', 'but', 'comes', 'common', 'date', 'day', 'didn', 'doesn', 'don', 'done', 'else', 'enough', 'every', 'everyth', 'excuse', 'flag', 'for', 'four', 'gives', 'go', 'gone', 'guy', 'half', 'happen', 'hasn', 'have', 'haven', 'he', 'head', 'him', 'if', 'ignor', 'in', 'it', 'just', 'later', 'like', 'm', 'make', 'me', 'met', 'miss', 'money', 'month', 'months', 'morn', 'much', 'my', 'new', 'night', 'number', 'of', 'on', 'or', 'out', 'point', 'r', 'rather', 'really', 'right?', 's', 'sav', 'see', 'semester', 'should', 'so', 'someth', 'sometimes', 'soon', 'start', 'stop', 't', 'talk', 'text', 'than', 'that', 'the', 'this', 'three', 'til', 'time', 'to', 'told', 'too', 'understand', 'up', 've', 'want', 'wants', 'was', 'wasn', 'we', 'week', 'went', 'what', 'whole', 'why', 'with', 'yet']\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "text1 = re.sub(\"([\\.!',\\)\\(\\\"])\", r\" \\1 \", text)\n",
    "text1 = re.sub(\"(\\s+)\", r\" \", text1)\n",
    "\n",
    "\n",
    "tok=text1.split(\" \")\n",
    "\n",
    "stemmed = []\n",
    "stem = [stemming(w) for w in tok]\n",
    "print(f\"Tokenizer makes {len(stem)} tokens, {len(set(stem))} types as follows:\\n{sorted(set(stem))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1) Think of more stemming rules\n",
    "\n",
    "2) Expand slang words in `code/data/slangWords.txt`\n",
    "- asap --> as soon as possible\n",
    "\n",
    "3) Clean, tokenize, stemming and count type/token `code/data/HTML.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task:\n",
    "# read slangWords.txt into a dictionary\n",
    "# map slang words into a dictionary\n",
    "# substitute slang words by full forms in the message text\n",
    "\n",
    "msg = \"I hope you enjoyed the conference in Melbourne. BTW Any suggestions for a good hotel there?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/kent/slee122/code/data/HTML.txt\n",
      "   Simone Biles: 'I blame system that enabled Larry Nassar abuse'     Published          1 hour ago                Share              close      Share page          Copy link    About sharing       Related Topics     Larry Nassar sex abuse scandal                   image source,  Getty Images        Elite US gymnast Simone Biles has testified before the Senate about abuse she suffered at the hands of disgraced former team doctor, Larry Nassar.        Former teammates Aly Raisman and McKayla Maroney also appeared before the committee, along with FBI Director Christopher Wray.      The committee is examining shortcomings in the FBI's investigation into Nassar, later convicted of sexually abusing girls.      He is serving a life sentence in jail.      \"I blame Larry Nasser, and I also blame an entire system that enabled and perpetrated his abuse,\" said Ms Biles, the most decorated Olympic gymnast of all-time.      \"If you allow a predator to harm children, the consequences will be swift and severe,\" she added.          SCATHING REPORT:  FBI failed to investigate USA Gymnastics abuser   VOICES:  What it was like to face 'monster' doctor in court         Gymnast Maggie Nichols - the first victim to report her abuse to USA Gymnastics - also testified.       They were some of the more than 200 women who gave powerful impact statements to a court in 2018, detailing Nassar's abuse when he was the sports doctor of the United States women's national gymnastics team.       A long-awaited report into the FBI's investigation , which was published in July, found numerous missteps and cover-ups by FBI agents, which allowed Nassar's abuse to continue for months after the case was first opened.      The 119-page report by the Department of Justice Inspector General found that despite the seriousness of the allegations against Nassar, the FBI field office in Indianapolis had been slow to respond.      Confronted by their mistakes, two FBI officials lied during interviews to cover up their errors, the report said. Last week, one of those officials was fired by the FBI, US media reported.               image source,  Reuters    image caption Olympic gymnasts Simone Biles, McKayla Maroney, Aly Raisman and Maggie Nichols      On Wednesday, Ms Raisman criticised the FBI's investigation as being \"like guesswork\", while Ms Maroney - who was the only victim initially interviewed by the agency - called her experience deeply disappointing.        \"They chose to fabricate, to lie about what I said and protect a serial child molester,\" Ms Maroney told the committee. \"What is the point of reporting abuse if our own FBI agents are going to take it upon themselves to bury that report in a drawer?\"      Chair Dick Durbin said Wednesday's Senate Judiciary Committee hearing would examine what had led to the failure of the FBI's investigation to \"prevent future, similar tragedies\".      Mr Wray is expected to face sharp questioning on the failings, and why agents found to have violated FBI policy were never prosecuted for their misconduct.      In total, Nassar was accused of sexual abuse by more than 330 women and girls at USA Gymnastics and Michigan State University.      Olympic gold medal winner Simone Biles is the most high profile victim to have spoken out about his abuse. After breaking her silence, Ms Biles said she was \"relieved\" after speaking out, after feeling \"a lot of pressure\" to keep the truth to herself for so long.      McKayla Maroney, who won gold at the London 2012 Olympic Games, has said she was sexually abused by Nassar over a seven-year period, starting when she was 13 years old.        \"It seemed whenever and wherever this man could find the chance, I was 'treated',\" she wrote on Twitter in 2017.               media caption Simone Biles speaks in 2018 about why sharing the abuse story will encourage others to come forward        Related Topics       Simone Biles    FBI    Larry Nassar sex abuse scandal    United States          More on this story             The 156 women who confronted a predator          Published   25 January 2018                   Why are some prison sentences so long?          Published   1 August 2013                   Abuse evidence 'empowered' me - Biles          Published   10 October 2018                   Athlete A - the questions explored in new Nassar scandal documentary          Published   24 June 2020                   Raisman criticises CEO's Nassar remarks          Published   26 April 2019                         What was it like to defend Larry Nassar?          Published   2 February 2018             \n"
     ]
    }
   ],
   "source": [
    "# task:\n",
    "# read HTML.txt from data directory (it is taken from https://www.bbc.com/news/world-us-canada-58573887)\n",
    "# - clean text\n",
    "# - tokenize text\n",
    "# - apply stemming rules\n",
    "# - count token / type ratio\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# get the path to HTML file\n",
    "p = Path('.') / 'data/HTML.txt'\n",
    "\n",
    "f = p\n",
    "print(f.resolve())\n",
    "\n",
    "# read the file\n",
    "with f.open('r', encoding='utf-8') as fhin:\n",
    "    data = fhin.read()\n",
    "\n",
    "data1 = re.sub(\"<[^>]*>\", \" \" , data)\n",
    "data1 = re.sub(\"&lt;[^&]*&gt;\", \"\" , data1)\n",
    "\n",
    "\n",
    "print(data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:1145, Types:393\n",
      "Tokens:1145, Types:393\n",
      "{'', 'disappointing.', 'found', 'reporting', 'been', 'Share', \"FBI's\", 'Mr', 'committee.', 'agents', 'predator', 'girls', '2017.', 'about', 'agents,', 'caption', '25', 'failings,', '\"What', 'herself', 'children,', 'against', 'up', 'evidence', 'their', 'examine', 'hour', 'Why', 'violated', '24', 'Wednesday,', '2013', 'Larry', 'criticised', ',', 'was', 'team.', 'cover', '-', 'hearing', 'chose', 'convicted', 'chance,', 'spoken', 'point', 'decorated', 'Abuse', 'into', 'Olympic', 'defend', 'Wray.', 'you', 'feeling', 'They', 'is', 'during', 'deeply', \"abuse'\", 'doctor', '200', 'April', 'won', 'if', 'statements', 'Copy', '\"I', 'Indianapolis', 'sexually', 'will', 'USA', 'misconduct.', 'allow', '\"If', 'sex', 'reported.', 'Athlete', 'why', 'page', 'Aly', \"'empowered'\", 'Simone', 'failure', 'State', 'field', 'Twitter', 'questioning', 'later', 'before', 'truth', 'has', '10', 'told', '156', 'Confronted', 'report', 'prison', 'experience', 'London', 'an', 'of', 'the', 'could', 'what', '26', 'two', 'interviewed', 'serving', '13', 'victim', 'court', 'those', 'Nassar,', 'wherever', 'accused', 'hands', '2012', 'Topics', '\"They', 'enabled', 'Inspector', 'at', 'abuse.', 'over', 'find', 'failed', 'he', 'Ms', 'former', 'are', 'After', '\"It', 'harm', 'said.', 'after', 'seven-year', 'breaking', 'wrote', \"Nassar's\", 'link', 'team', 'August', 'REPORT:', 'FBI', 'new', 'like', 'case', '\"relieved\"', 'swift', 'medal', 'ago', 'Gymnastics', 'disgraced', '2019', 'who', \"CEO's\", 'perpetrated', 'speaks', 'Nassar.', 'silence,', 'published', 'have', 'take', 'than', 'girls.', 'abused', 'guesswork\",', 'confronted', '2018,', 'she', 'allowed', 'opened.', 'Director', '\"a', 'protect', 'child', 'Biles', 'some', 'He', 'never', '330', \"Wednesday's\", 'appeared', 'bury', 'Nichols', 'blame', 'out', 'lie', 'investigate', 'sexual', 'gold', 'powerful', 'tragedies\".', 'others', 'Published', 'Getty', 'Raisman', 'gave', 'committee', 'sharing', 'gymnastics', 'me', 'continue', 'Senate', 'long?', 'winner', 'Elite', 'teammates', 'gymnasts', 'Maggie', 'initially', 'expected', 'examining', 'first', 'Images', 'molester,\"', 'Michigan', 'out,', 'along', 'University.', 'Judiciary', 'Biles:', 'future,', 'in', 'were', 'sentences', 'Durbin', 'General', 'respond.', 'Nassar', 'entire', 'questions', 'About', 'abuse', 'had', 'Christopher', 'all-time.', 'media', '\"prevent', 'On', '2018', 'Chair', 'July,', 'jail.', 'Biles,', 'one', 'What', 'it', 'SCATHING', 'would', 'detailing', 'Last', 'lied', 'on', 'errors,', '2020', \"'I\", 'officials', '2', 'mistakes,', 'Justice', 'come', 'numerous', 'said', 'Nasser,', 'period,', 'Gymnast', 'long-awaited', 'suffered', 'VOICES:', 'fired', 'his', 'months', 'being', 'FBI,', 'Dick', 'Former', '\\'treated\\',\"', 'also', 'Nassar?', 'cover-ups', 'I', \"'monster'\", 'image', 'with', 'impact', 'January', 'documentary', 'abuser', 'severe,\"', 'criticises', 'February', 'More', 'explored', 'for', 'seriousness', 'drawer?\"', \"women's\", 'week,', 'lot', 'June', 'sentence', 'so', 'to', 'when', 'called', 'this', 'despite', 'scandal', 'Maroney', '\"like', 'prosecuted', 'starting', 'Department', 'source,', 'doctor,', 'fabricate,', 'forward', 'policy', 'US', 'seemed', 'interviews', 'story', 'allegations', 'committee,', 'sharp', 'missteps', 'pressure\"', 'only', 'system', 'testified', '1', 'which', '119-page', 'by', 'encourage', 'and', 'slow', 'profile', 'Related', 'abuse,\"', 'as', 'that', 'investigation', 'themselves', 'October', 'Wray', 'shortcomings', 'McKayla', 'own', 'speaking', 'testified.', 'national', 'most', 'sports', 'keep', 'high', 'while', 'States', 'long.', 'upon', 'office', 'a', 'life', 'Committee', 'United', 'In', 'close', 'Reuters', 'Maroney,', 'our', 'years', 'face', 'more', 'agency', 'her', 'consequences', 'total,', 'women', 'be', 'gymnast', 'old.', 'The', 'serial', 'remarks', 'added.', 'similar', 'abusing', 'man', 'going', 'Games,', 'whenever', 'A', 'led'}\n"
     ]
    }
   ],
   "source": [
    "data1 = re.split(\"\\s\", data1)\n",
    "print(f\"Tokens:{len(data1)}, Types:{len(set(data1))}\")\n",
    "\n",
    "# your cleaning code here\n",
    "\n",
    "\n",
    "print(f\"Tokens:{len(data1)}, Types:{len(set(data1))}\\n{set(data1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
