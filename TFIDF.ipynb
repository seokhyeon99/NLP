{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task:\n",
    "# sort TF-IDF \n",
    "# extract top 5 words\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import nltk\n",
    "\n",
    "# import nltk books\n",
    "#from nltk.book import *\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "def preprocessSent(sent, tag = True):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    if(tag == True):  sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "def preprocessText(text, tag = True):\n",
    "# Segment text into sentences\n",
    "    sent = sent_tokenize(text)\n",
    "# Tokenize each sentences\n",
    "    sent = [nltk.word_tokenize(s) for s in sent]\n",
    "# Part-of-speech tagging each sentences\n",
    "    if(tag == True) : sent = [nltk.pos_tag(s) for s in sent]\n",
    "    return sent\n",
    "\n",
    "# Read n files from directory and preprocess\n",
    "# D[doc][sent][word]\n",
    "\n",
    "def ReadSourceTok(dic, n=100,  tag = False) :\n",
    "    D = {}\n",
    "    i = 0\n",
    "    for f in sorted(Path(dic).iterdir()):\n",
    "        print(f.resolve())\n",
    "        if (i == n): break\n",
    "        i += 1\n",
    "        with f.open('r', encoding='utf-8') as fhin:\n",
    "            data = fhin.read()\n",
    "        b = os.path.basename(f)\n",
    "        D.setdefault(b, [])\n",
    "        D[b].append(preprocessSent(data, tag = tag))\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "def f(t, d):\n",
    "    # d is document == tokens\n",
    "    return d.count(t)\n",
    "\n",
    "def tf(t, d):\n",
    "    # d is document == tokens\n",
    "    return 0.5 + 0.5*f(t,d)/max([f(w,d) for w in d])\n",
    "\n",
    "def idf(t, D):\n",
    "    # D is documents == document list\n",
    "    numerator = len(D)\n",
    "    denominator = 1 + len([ True for d in D if t in d])\n",
    "    return log10(numerator/denominator)\n",
    "\n",
    "def tfidf(t, d, D):\n",
    "    return tf(t,d)*idf(t, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/kent/slee122/code/data/text_file/0_10.txt\n",
      "/users/kent/slee122/code/data/text_file/10000_7.txt\n",
      "/users/kent/slee122/code/data/text_file/10001_9.txt\n",
      "/users/kent/slee122/code/data/text_file/10002_8.txt\n"
     ]
    }
   ],
   "source": [
    "D = ReadSourceTok(\"/users/kent/slee122/code/data/text_file/\", n=4,  tag = False)\n",
    "D1 = []\n",
    "for i in D.keys():\n",
    "    D1.append(D[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file 0 :went  last  night  after  coaxed  \n",
      "file 1 :Actor  or  turned  director  Bill  \n",
      "file 2 :As  recreational  golfer  knowledge  history  \n",
      "file 3 :sneak  preview  delightful  cinematography  unusually  \n"
     ]
    }
   ],
   "source": [
    "result_0 = []\n",
    "result_1 = []\n",
    "result_2 = []\n",
    "result_3 = []\n",
    "sorted_result = []\n",
    "for i in range(len(D1)):\n",
    "    for j in D1[i]:\n",
    "        if i == 0:\n",
    "            result_0.append([j, tfidf(j,D1[i][0],D1)])#t-str,d-list,D-2d list\n",
    "        elif i == 1:\n",
    "            result_1.append([j, tfidf(j,D1[i][0],D1)])#t-str,d-list,D-2d list\n",
    "        elif i == 2:\n",
    "            result_2.append([j, tfidf(j,D1[i][0],D1)])#t-str,d-list,D-2d list\n",
    "        elif i == 3:\n",
    "            result_3.append([j, tfidf(j,D1[i][0],D1)])#t-str,d-list,D-2d list\n",
    "sorted_result.append(sorted(result_0, key=lambda x: x[1], reverse=True))\n",
    "sorted_result.append(sorted(result_1, key=lambda x: x[1], reverse=True))\n",
    "sorted_result.append(sorted(result_2, key=lambda x: x[1], reverse=True))\n",
    "sorted_result.append(sorted(result_3, key=lambda x: x[1], reverse=True))\n",
    "\n",
    "for i in range(len(D1)):\n",
    "    print('file', i, ':', end='')\n",
    "    for j in range(5):\n",
    "        print(sorted_result[i][j][0], ' ', end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
